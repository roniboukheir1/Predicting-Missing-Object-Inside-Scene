{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b0991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e0ada4b-ed74-4d9f-9f71-0bb097d28905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "from pycocotools.coco import COCO\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52235a76-72e9-49e4-afaf-95f4d5edf465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=5.28s)\n",
      "creating index...\n",
      "index created!\n",
      "Number of images in the original 'train2017' directory: 118287\n",
      "Processing complete. Modified images and annotations are saved.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Path to the annotations file\n",
    "annotations_path = 'annotations/instances_train2017.json'\n",
    "\n",
    "# Initialize COCO API for instance annotations\n",
    "coco = COCO(annotations_path)\n",
    "\n",
    "# Get all image ids\n",
    "image_ids = coco.getImgIds()\n",
    "\n",
    "# Modified annotations dictionary\n",
    "modified_annotations = {'images': [], 'annotations': [], 'categories': coco.loadCats(coco.getCatIds())}\n",
    "\n",
    "count = 0\n",
    "# Process each image\n",
    "for image_id in image_ids:\n",
    "    # Load image information\n",
    "    image_info = coco.loadImgs(image_id)[0]\n",
    "    \n",
    "    # Load annotations for this image\n",
    "    ann_ids = coco.getAnnIds(imgIds=image_id)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "    # Skip images with no annotations\n",
    "    if not anns:\n",
    "        continue\n",
    "\n",
    "    # Randomly choose an annotation to delete\n",
    "    index_to_remove = random.randint(0, len(anns) - 1)\n",
    "    deleted_ann = anns.pop(index_to_remove)  # Remove the chosen annotation\n",
    "\n",
    "    # Add image info and deleted object name to modified annotations\n",
    "    modified_annotations['images'].append({\n",
    "        'id': image_info['id'],\n",
    "        'file_name': image_info['file_name'],\n",
    "        'deleted_object': coco.loadCats([deleted_ann['category_id']])[0]['name']\n",
    "    })\n",
    "\n",
    "    # Add remaining annotations to the modified list\n",
    "    modified_annotations['annotations'].extend(anns)\n",
    "\n",
    "# Save the modified annotations to a new JSON file\n",
    "with open('modified_instances_train2017.json', 'w') as f:\n",
    "    json.dump(modified_annotations, f)\n",
    "\n",
    "print(\"Modified annotations have been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b503a695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ./modified_train2017\n",
      "Skipping image 000000391895.jpg as it does not exist.\n",
      "Skipping image 000000522418.jpg as it does not exist.\n",
      "Opened image: ./train2017\\000000184613.jpg\n",
      "Saved modified image: ./modified_train2017\\cow.jpg\n",
      "Skipping image 000000318219.jpg as it does not exist.\n",
      "Skipping image 000000554625.jpg as it does not exist.\n",
      "Skipping image 000000574769.jpg as it does not exist.\n",
      "Opened image: ./train2017\\000000060623.jpg\n",
      "Saved modified image: ./modified_train2017\\dining table.jpg\n",
      "Skipping image 000000309022.jpg as it does not exist.\n",
      "Opened image: ./train2017\\000000005802.jpg\n",
      "Saved modified image: ./modified_train2017\\cup.jpg\n",
      "Opened image: ./train2017\\000000222564.jpg\n",
      "Saved modified image: ./modified_train2017\\oven.jpg\n"
     ]
    }
   ],
   "source": [
    "# Path to the annotations file and images directory\n",
    "annotations_path = './annotations/instances_train2017.json'\n",
    "images_directory = './train2017'\n",
    "modified_images_directory = './modified_train2017'\n",
    "\n",
    "# Load the annotations\n",
    "with open(annotations_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Mapping of category IDs to category names\n",
    "category_mapping = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "\n",
    "# Ensure the modified images directory exists\n",
    "if not os.path.exists(modified_images_directory):\n",
    "    os.makedirs(modified_images_directory)\n",
    "    print(f\"Created directory: {modified_images_directory}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {modified_images_directory}\")\n",
    "\n",
    "# Function to mask the deleted object\n",
    "def mask_deleted_object(image, annotation):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    bbox = annotation['bbox']\n",
    "    draw.rectangle([\n",
    "        (bbox[0], bbox[1]), \n",
    "        (bbox[0] + bbox[2], bbox[1] + bbox[3])\n",
    "    ], fill='white')\n",
    "    return image\n",
    "\n",
    "# Process three images as an example\n",
    "for image_info in data['images']:  # Adjust the slice for more or fewer images\n",
    "    image_path = os.path.join(images_directory, image_info['file_name'])\n",
    "    \n",
    "    # Check if image file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Skipping image {image_info['file_name']} as it does not exist.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        print(f\"Opened image: {image_path}\")\n",
    "\n",
    "        # Get annotations for this image\n",
    "        ann_ids = [ann['id'] for ann in data['annotations'] if ann['image_id'] == image_info['id']]\n",
    "        annotations = [ann for ann in data['annotations'] if ann['id'] in ann_ids]\n",
    "\n",
    "        # Randomly delete one annotation if there are any\n",
    "        if annotations:\n",
    "            random_ann_to_remove = random.choice(annotations)\n",
    "            annotations.remove(random_ann_to_remove)\n",
    "\n",
    "            # Mask the deleted object on the image\n",
    "            image = mask_deleted_object(image, random_ann_to_remove)\n",
    "            deleted_object_name = category_mapping[random_ann_to_remove['category_id']]\n",
    "\n",
    "            # Save the modified image\n",
    "            modified_image_path = os.path.join(modified_images_directory, f\"{deleted_object_name}.jpg\")\n",
    "    \n",
    "            image.save(modified_image_path)\n",
    "\n",
    "            print(f\"Saved modified image: {modified_image_path}\")\n",
    "        else:\n",
    "            print(f\"No annotations found for image {image_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_info['file_name']}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b6837-6b05-40c3-8914-6634602e5dc5",
   "metadata": {},
   "source": [
    "# Preparing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab0d2cc4-f6c4-438f-b8c3-295f430e96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_url = 'https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn'\n",
    "\n",
    "num_steps = 50000\n",
    "num_eval_steps = 50\n",
    "\n",
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
    "        'batch_size': 12\n",
    "    }\n",
    "}\n",
    "\n",
    "selected_model = 'ssd_mobilenet_v2'\n",
    "\n",
    "# Name of the object detection model to use.\n",
    "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
    "\n",
    "# Name of the pipline file in tensorflow object detection API.\n",
    "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
    "\n",
    "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
    "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a443d",
   "metadata": {},
   "source": [
    "### Convert Images and Annotations to TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fe385e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()  # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def create_tf_example(image_path):\n",
    "    # Load image\n",
    "    with tf.io.gfile.GFile(image_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = tf.io.decode_jpeg(encoded_jpg)\n",
    "\n",
    "    width, height = Image.open(image_path).size\n",
    "\n",
    "    # Define your features\n",
    "    feature = {\n",
    "        'image/encoded': _bytes_feature(encoded_jpg),\n",
    "        'image/format': _bytes_feature(b'jpeg'),\n",
    "        'image/width': _int64_feature(width),\n",
    "        'image/height': _int64_feature(height),\n",
    "    }\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example\n",
    "\n",
    "def main(output_path, image_directory):\n",
    "    writer = tf.io.TFRecordWriter(output_path)\n",
    "    \n",
    "    # List all image files\n",
    "    image_files = [f for f in os.listdir(image_directory) if f.endswith('.jpg')]\n",
    "    for image_file in image_files:\n",
    "        tf_example = create_tf_example(os.path.join(image_directory, image_file))\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "main('train.tfrecord', './modified_train2017')  # Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c146377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    raw_dataset = tf.data.TFRecordDataset(filename)\n",
    "\n",
    "    # Create a dictionary describing the features.\n",
    "    image_feature_description = {\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/format': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    def _parse_image_function(example_proto):\n",
    "        return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "    parsed_image_dataset = raw_dataset.map(_parse_image_function)\n",
    "    return parsed_image_dataset\n",
    "\n",
    "# Example of loading the dataset\n",
    "train_dataset = load_dataset('train.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "965cb06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = sum(1 for _ in train_dataset)\n",
    "\n",
    "# Define the split point for training and testing, for example 80% for training\n",
    "train_size = int(0.8 * DATASET_SIZE)\n",
    "test_size = DATASET_SIZE - train_size\n",
    "\n",
    "# Shuffle the dataset\n",
    "dataset = train_dataset.shuffle(buffer_size=DATASET_SIZE)\n",
    "\n",
    "# Split the dataset into training and testing\n",
    "train_dataset = dataset.take(train_size)\n",
    "test_dataset = dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1aff9a74-678c-4abf-a988-2e24e8a16cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/johnchidiac/DeepLearning\n",
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 97132, done.\u001b[K\n",
      "remote: Counting objects: 100% (412/412), done.\u001b[K\n",
      "remote: Compressing objects: 100% (199/199), done.\u001b[K\n",
      "error: RPC failed; curl 92 HTTP/2 stream 0 was not closed cleanly: CANCEL (err 8)\n",
      "error: 2183 bytes of body are still expected\n",
      "fetch-pack: unexpected disconnect while reading sideband packet\n",
      "fatal: early EOF\n",
      "fatal: fetch-pack: invalid index-pack output\n"
     ]
    }
   ],
   "source": [
    "%cd /home/johnchidiac/DeepLearning\n",
    "!git clone https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52ab276e-f96c-40b7-bcd3-2123a8375591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-25 04:56:58--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/dataset_tools/create_coco_tf_record.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 22961 (22K) [text/plain]\n",
      "Saving to: ‘create_coco_tf_record.py’\n",
      "\n",
      "create_coco_tf_reco 100%[===================>]  22.42K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-04-25 04:56:58 (208 KB/s) - ‘create_coco_tf_record.py’ saved [22961/22961]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/dataset_tools/create_coco_tf_record.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60d9d550-da3d-4f56-8b98-0e41d5468e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/johnchidiac/DeepLearning/output_tfrecords': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%ls /home/johnchidiac/DeepLearning/output_tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5fbf7af9-7a25-4b56-9dd9-2c47022d6346",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /home/johnchidiac/DeepLearning/output_tfrecords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cfbb7a-f286-4ffe-9c09-cd9c8dae8aac",
   "metadata": {},
   "source": [
    "# Script to generate TFRecords and it skips the missing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65613c45-c5b2-44bb-bd29-c4e40e19c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import io\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "from pycocotools import mask\n",
    "from object_detection.utils import dataset_util as du\n",
    "\n",
    "def create_tf_example(image, annotations_list, image_dir, category_index, include_masks=False, include_keypoints=False):\n",
    "    image_path = os.path.join(image_dir, image['file_name'])\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Skipping missing file: {}\".format(image_path))\n",
    "        return None, 0, 0, 0\n",
    "\n",
    "    with tf.io.gfile.GFile(image_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = PIL.Image.open(encoded_jpg_io)\n",
    "    if image.format != 'JPEG':\n",
    "        raise ValueError('Image format not JPEG')\n",
    "    key = hashlib.sha256(encoded_jpg).hexdigest()\n",
    "\n",
    "    width = int(image.width)\n",
    "    height = int(image.height)\n",
    "\n",
    "    xmin = []\n",
    "    xmax = []\n",
    "    ymin = []\n",
    "    ymax = []\n",
    "    is_crowd = []\n",
    "    category_names = []\n",
    "    category_ids = []\n",
    "    area = []\n",
    "    encoded_mask_png = []\n",
    "\n",
    "    for object_annotations in annotations_list:\n",
    "        (x, y, width, height) = tuple(object_annotations['bbox'])\n",
    "        if width <= 0 or height <= 0:\n",
    "            continue\n",
    "        if x + width > image.width or y + height > image.height:\n",
    "            continue\n",
    "        xmin.append(float(x) / image.width)\n",
    "        xmax.append(float(x + width) / image.width)\n",
    "        ymin.append(float(y) / image.height)\n",
    "        ymax.append(float(y + height) / image.height)\n",
    "        is_crowd.append(object_annotations['iscrowd'])\n",
    "        category_ids.append(int(object_annotations['category_id']))\n",
    "        category_names.append(category_index[object_annotations['category_id']]['name'].encode('utf8'))\n",
    "        area.append(object_annotations['area'])\n",
    "\n",
    "        if include_masks:\n",
    "            run_len_encoding = mask.frPyObjects(object_annotations['segmentation'], image.height, image.width)\n",
    "            binary_mask = mask.decode(run_len_encoding)\n",
    "            pil_image = PIL.Image.fromarray(binary_mask)\n",
    "            output_io = io.BytesIO()\n",
    "            pil_image.save(output_io, format='PNG')\n",
    "            encoded_mask_png.append(output_io.getvalue())\n",
    "\n",
    "    feature_dict = {\n",
    "        'image/height': du.int64_feature(height),\n",
    "        'image/width': du.int64_feature(width),\n",
    "        'image/filename': du.bytes_feature(image['file_name'].encode('utf8')),\n",
    "        'image/source_id': du.bytes_feature(image['file_name'].encode('utf8')),\n",
    "        'image/key/sha256': du.bytes_feature(key.encode('utf8')),\n",
    "        'image/encoded': du.bytes_feature(encoded_jpg),\n",
    "        'image/format': du.bytes_feature('jpeg'.encode('utf8')),\n",
    "        'image/object/bbox/xmin': du.float_list_feature(xmin),\n",
    "        'image/object/bbox/xmax': du.float_list_feature(xmax),\n",
    "        'image/object/bbox/ymin': du.float_list_feature(ymin),\n",
    "        'image/object/bbox/ymax': du.float_list_feature(ymax),\n",
    "        'image/object/class/text': du.bytes_list_feature(category_names),\n",
    "        'image/object/class/label': du.int64_list_feature(category_ids),\n",
    "        'image/object/is_crowd': du.int64_list_feature(is_crowd),\n",
    "        'image/object/area': du.float_list_feature(area),\n",
    "    }\n",
    "\n",
    "    if include_masks:\n",
    "        feature_dict['image/object/mask'] = du.bytes_list_feature(encoded_mask_png)\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "    return example, len(xmin), 0, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c704eb-e4d2-4ee2-bd5e-2fecd7fc7f4d",
   "metadata": {},
   "source": [
    "## Installing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4aad05f0-394a-43cf-9094-264250e07674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/johnchidiac/DeepLearning/content\n",
      "Cloning into 'tensorflow-object-detection-faster-rcnn'...\n",
      "remote: Enumerating objects: 885, done.\u001b[K\n",
      "remote: Total 885 (delta 0), reused 0 (delta 0), pack-reused 885\u001b[K\n",
      "Receiving objects: 100% (885/885), 24.83 MiB | 1.46 MiB/s, done.\n",
      "Resolving deltas: 100% (428/428), done.\n",
      "/home/johnchidiac/DeepLearning/content/tensorflow-object-detection-faster-rcnn\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "%cd ./content\n",
    "\n",
    "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
    "\n",
    "!git clone {repo_url}\n",
    "%cd {repo_dir_path}\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7960a-8aca-4595-a934-82c334989713",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!git clone --quiet https://github.com/tensorflow/models.git\n",
    "\n",
    "!pip install tf_slim\n",
    "\n",
    "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
    "\n",
    "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
    "\n",
    "!pip install -q pycocotools\n",
    "\n",
    "!pip install lvis\n",
    "\n",
    "%cd /content/models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
    "\n",
    "!pip install numpy==1.19.5\n",
    "!pip uninstall -y pycocotools\n",
    "!pip install pycocotools --no-binary pycocotools\n",
    "\n",
    "!python object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b90b8-b13c-49e2-b07a-ca75e19e4ed7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
